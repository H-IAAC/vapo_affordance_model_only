defaults:
  - paths: general_paths
  - aff_model@model_cfg: default
  - camera_conf: tabletop_render # Uses tabletop_sideview.yaml (placeholder for test data)
  - transforms@affordance.transforms: aff_transforms
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog

get_eval_files: False

n_epochs: 50
rand_crop: 0.8

model_cfg:
  n_classes: 2
  input_channels: 3 


# load model
gripper_cam_aff_path: ${paths.trained_models}/affordance/gripper_tabletop.ckpt
static_cam_aff_path: ${paths.trained_models}/affordance/static_tabletop.ckpt
model_path: ${static_cam_aff_path}
model_name: vapo

test:
  folder_name: ${paths.vapo_path}/trained_models/policy/tabletop/vapo

# Path for image input dataset
dataset_name: tabletop
data_dir: ${paths.datasets}/${dataset_name}
dataset:
  cam: static
  img_resize:
      static: 200
      gripper: 64
      all: 100  # Resize to this if using all images
  radius:
      static: 14
      gripper: 10

dataloader:
  num_workers: 4
  batch_size: 128
  pin_memory: true

trainer:
  gpus: -1
  max_epochs: ${n_epochs}
  num_sanity_val_steps: 1
  strategy: ddp
  precision: 16

wandb:
  project: affordance_model
  mode: offline

# For visualization
calculate_gt: False  # Calculate ground truth affordances from data in the npz files
target_height_override: True # If flag is true, then the target selected is the highest point instead of most robust

# The detected object center may not be perfectly aligned with the actual handle. Use this to
# find the handle by depth too. Feature used on original repository on simulation mode.
find_handle_by_depth: False

out_size: 200
save_images: False
imshow: True
output_dir: ./predictions/

#-- Hydra config --#
# hydra output will be stored to save_dir
save_dir: ./hydra_outputs/viz/
hydra:
  run:
    dir: ${save_dir}${now:%Y-%m-%d}/${now:%H-%M-%S} # Output directory for normal runs
